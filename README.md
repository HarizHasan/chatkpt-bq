# chatkpt-bq
New revision of ChatKPT leveraging BigQuery ML.
ChatKPT is an RAG program utilizing Vertex AI and Gemini 2.0 via BigQuery ML models in order to process, store, retrieve, and generate responses for queries provided as strings. ChatKPT can be deployed as an API endpoint utilizing [https://github.com/fastapi/fastapi](FastAPI).

# Setup
Ensure you have the [https://cloud.google.com/sdk/docs/install](Google Cloud CLI installed), and that you are [https://cloud.google.com/docs/authentication/gcloud](authenticated).  
Ensure your Google Cloud project has all relevant APIs (ie. Vertex AI API, BigQuery Connection API, etc.), enabled and that a Vertex AI connection has been set up with BigQuery (grant the service account the Vertex AI User permission).  
On first start up run chatkpt.py with --update-db --initial-setup for first time run.  
Afterwards, you can simply run with --update-db for updating the database.

# Variables
Environment variables to be defined via dotenv:

**PROJECT_ID** - Name of Google Cloud Project  
**LOCATION** - Location of Google Cloud resources (Cloud Storage, BigQuery, etc.)  
**DATASET_ID** - BigQuery dataset ID  
**KNOWLEDGE_BASE_TABLE_ID** - ID of table where documents will be loaded.  
**EMBEDDING_TABLE_ID** - ID of table where embeddings will be stored.  
**EMBEDDING_MODEL_ID** - ID of BigQuery ML model that will generate embeddings.  
**GENERATIVE_MODEL_ID** - ID of BigQuery ML model that will generate responses based on RAG retrieval.  
**CONNECTION_NAME** - ID of BigQuery-Vertex AI connection.  
**GCS_BUCKET_NAME** - ID of bucket where documents to be processed are stored.  
**GCS_FOLDER_PATH** - ID of folder in bucket where documents are stored, if any (leave as "" if N/A)  
**EMBEDDING_MODEL_ENDPOINT** - Endpoint ID of Google embedding model that will be used (recommended to use "text-embedding-005")  
**GENERATIVE_MODEL_ENDPOINT** - Endpoint ID of Google LLM that will be used. Refer to [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model](Google Cloud documentation) on available models and how to structure the endpoint (use of a global endpoint is recommended).

# Endpoints
ChatKPT has two endpoints.

**/query** - Takes a simple string, queries BigQuery via BigQuery ML, and returns a response generated by Gemini 2.0.  
**/health** - Regular health check.  

# Deploying
If you wish to deploy this as an API endpoint, ensure that the service account used to deploy the API has the appropriate roles - bigquery.jobUser and bigquery.user. The Dockerfile is provided.